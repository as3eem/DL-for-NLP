{"cells":[{"metadata":{"_uuid":"3a184cf39b80e4f3ded8afb4d4a59a905915f1b4"},"cell_type":"markdown","source":"# CNN for Sentence Classification"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":3,"outputs":[{"output_type":"stream","text":"['glove-global-vectors-for-word-representation', 'movie-review-sentiment-analysis-kernels-only']\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"08c3425b67173c7162a586c06cbb279f29f946a9"},"cell_type":"code","source":"# lets import some stuff\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.initializers import Constant\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.utils.np_utils import to_categorical\nimport re\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e0fe2cee592ee4313e67b342fffdd9bb851578d"},"cell_type":"code","source":"df = pd.read_csv('../input/movie-review/data.tsv', delimiter='\\t')\ndf = df[['Phrase', 'new_sent']]\ndf.columns= [\"Phrase\", \"Sentiment\"]\npd.set_option('display.max_colwidth', -1)\ndf.head(3)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                                                                                                   Phrase  Sentiment\n0  , this is one adapted - from-television movie that actually looks as if it belongs on the big screen .                  1        \n1  fails to give his audience a single character worth rooting for -LRB- or worth rooting against , for that matter -RRB-  0        \n2  A dark comedy that goes for sick and demented humor simply to do so .                                                   0        ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>, this is one adapted - from-television movie that actually looks as if it belongs on the big screen .</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fails to give his audience a single character worth rooting for -LRB- or worth rooting against , for that matter -RRB-</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A dark comedy that goes for sick and demented humor simply to do so .</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"1560d4c17410b19f0d420f4afb074e0721b15e56"},"cell_type":"code","source":"def clean_str(in_str):\n    in_str = str(in_str)\n    # replace urls with 'url'\n    in_str = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\", \"url\", in_str)\n    in_str = re.sub(r'([^\\s\\w]|_)+', '', in_str)\n    return in_str.strip().lower()\n\n\ndf['text'] = df['Phrase'].apply(clean_str)\ndata = df","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a42e34a57fa9e55a4a613ce60d7b5f6314a6faf"},"cell_type":"code","source":"df.Sentiment.value_counts()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"1    6000\n0    6000\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"25e8946dae515f87a21959d4387566de945d2154"},"cell_type":"markdown","source":"Now, we need to tokenize our sentences into vectors. Before we do that we need to pick a vector size."},{"metadata":{"trusted":true,"_uuid":"ec44d5d08736cf56b40718228427a50f7355f1f1"},"cell_type":"code","source":"data['l'] = data['Phrase'].apply(lambda x: len(str(x).split(' ')))\nprint(\"mean length of sentence: \" + str(data.l.mean()))\nprint(\"max length of sentence: \" + str(data.l.max()))\nprint(\"std dev length of sentence: \" + str(data.l.std()))","execution_count":15,"outputs":[{"output_type":"stream","text":"mean length of sentence: 18.754\nmax length of sentence: 52\nstd dev length of sentence: 6.937518391335498\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"0c546ced21a6fc3e8ffb9747e192e7da364911a2"},"cell_type":"code","source":"# these sentences aren't that long so we may as well use the whole string\nsequence_length = 52","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7d26ca92f2f3bf193df765fa1621d85bdf22297"},"cell_type":"code","source":"max_features = 20000 # this is the number of words we care about\n\ntokenizer = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>')\ntokenizer.fit_on_texts(data['Phrase'].values)\n\n# this takes our sentences and replaces each word with an integer\nX = tokenizer.texts_to_sequences(data['Phrase'].values)\n\n# we then pad the sequences so they're all the same length (sequence_length)\nX = pad_sequences(X, sequence_length)\n\ny = pd.get_dummies(data['Sentiment']).values\n\n# where there isn't a test set, Kim keeps back 10% of the data for testing, I'm going to do the same since we have an ok amount to play with\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nprint(\"test set size \" + str(len(X_test)))","execution_count":19,"outputs":[{"output_type":"stream","text":"test set size 2400\n","name":"stdout"}]},{"metadata":{"_uuid":"c34ecf0298d9a96625397833231ff872723e96f3"},"cell_type":"markdown","source":"#Â Model 1: Glove Embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 50\nnum_filters = 100\n\ninputs = Input(shape=(sequence_length,), dtype='int32')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce8803408785f0222cdb4d424c574135fe0b8d2e"},"cell_type":"code","source":"embeddings_index = {}\nf = open(os.path.join('../input/glove-global-vectors-for-word-representation/', 'glove.6B.50d.txt'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","execution_count":36,"outputs":[{"output_type":"stream","text":"Found 400000 word vectors.\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"573d5e1e5b170a77f61ab66990ba4cb6bc8b66a4"},"cell_type":"code","source":"word_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":37,"outputs":[{"output_type":"stream","text":"Found 12599 unique tokens.\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"6ab06dd855b04f70166527630ffdbe72b64d7d0f"},"cell_type":"code","source":"num_words = min(max_features, len(word_index)) + 1\nprint(num_words)\n\n# first create a matrix of zeros, this is our embedding matrix\nembedding_matrix = np.zeros((num_words, embedding_dim))\n\n# for each word in our tokenizer lets try to find that work in our w2v model\nfor word, i in word_index.items():\n    if i > max_features:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # we found the word - add that words vector to the matrix\n        embedding_matrix[i] = embedding_vector\n    else:\n        # doesn't exist, assign a random vector\n        embedding_matrix[i] = np.random.randn(embedding_dim)","execution_count":38,"outputs":[{"output_type":"stream","text":"12600\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"e63faa267307e89d72ecc591de05b6ae036d3c50"},"cell_type":"code","source":"inputs_2 = Input(shape=(sequence_length,), dtype='int32')\n\n# note the `trainable=False`, later we will make this layer trainable\nembedding_layer_2 = Embedding(num_words,\n                            embedding_dim,\n                            embeddings_initializer=Constant(embedding_matrix),\n                            input_length=sequence_length,\n                            trainable=False)(inputs_2)\n\nreshape_2 = Reshape((sequence_length, embedding_dim, 1))(embedding_layer_2)\n\nconv_0_2 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_2)\nconv_1_2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_2)\nconv_2_2 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_2)\n\nmaxpool_0_2 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_2)\nmaxpool_1_2 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_2)\nmaxpool_2_2 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_2)\n\nconcatenated_tensor_2 = Concatenate(axis=1)([maxpool_0_2, maxpool_1_2, maxpool_2_2])\nflatten_2 = Flatten()(concatenated_tensor_2)\n\ndropout_2 = Dropout(0.5)(flatten_2)\noutput_2 = Dense(units=2, activation='softmax')(dropout_2)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33cd071c9b72e11641ef8c53fc016ef2ddc42aa4"},"cell_type":"code","source":"model_2 = Model(inputs=inputs_2, outputs=output_2)\nmodel_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model_2.summary())","execution_count":43,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            (None, 52)           0                                            \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 52, 50)       630000      input_5[0][0]                    \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 52, 50, 1)    0           embedding_5[0][0]                \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 50, 1, 100)   15100       reshape_5[0][0]                  \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 49, 1, 100)   20100       reshape_5[0][0]                  \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 48, 1, 100)   25100       reshape_5[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_13 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_14 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_15 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 3, 1, 100)    0           max_pooling2d_13[0][0]           \n                                                                 max_pooling2d_14[0][0]           \n                                                                 max_pooling2d_15[0][0]           \n__________________________________________________________________________________________________\nflatten_5 (Flatten)             (None, 300)          0           concatenate_5[0][0]              \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 300)          0           flatten_5[0][0]                  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 2)            602         dropout_5[0][0]                  \n==================================================================================================\nTotal params: 690,902\nTrainable params: 60,902\nNon-trainable params: 630,000\n__________________________________________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"0ac83b5caf0d64aac8aea8debac7d731d60cc4ca"},"cell_type":"code","source":"batch_size = 32\nhistory_2 = model_2.fit(X_train, y_train, epochs=30, batch_size=batch_size, verbose=1, validation_split=0.2)","execution_count":44,"outputs":[{"output_type":"stream","text":"Train on 7680 samples, validate on 1920 samples\nEpoch 1/30\n7680/7680 [==============================] - 2s 220us/step - loss: 1.1849 - acc: 0.5379 - val_loss: 0.7097 - val_acc: 0.5089\nEpoch 2/30\n7680/7680 [==============================] - 1s 140us/step - loss: 0.7109 - acc: 0.5305 - val_loss: 0.7086 - val_acc: 0.5115\nEpoch 3/30\n7680/7680 [==============================] - 1s 184us/step - loss: 0.7094 - acc: 0.5266 - val_loss: 0.7081 - val_acc: 0.4958\nEpoch 4/30\n7680/7680 [==============================] - 1s 150us/step - loss: 0.7072 - acc: 0.5258 - val_loss: 0.7064 - val_acc: 0.5047\nEpoch 5/30\n7680/7680 [==============================] - 1s 152us/step - loss: 0.7063 - acc: 0.5215 - val_loss: 0.7047 - val_acc: 0.5073\nEpoch 6/30\n7680/7680 [==============================] - 1s 150us/step - loss: 0.7027 - acc: 0.5167 - val_loss: 0.7007 - val_acc: 0.5047\nEpoch 7/30\n7680/7680 [==============================] - 1s 143us/step - loss: 0.6995 - acc: 0.5043 - val_loss: 0.6974 - val_acc: 0.4958\nEpoch 8/30\n7680/7680 [==============================] - 1s 142us/step - loss: 0.6987 - acc: 0.5121 - val_loss: 0.6986 - val_acc: 0.5042\nEpoch 9/30\n7680/7680 [==============================] - 1s 145us/step - loss: 0.6979 - acc: 0.5163 - val_loss: 0.6981 - val_acc: 0.5068\nEpoch 10/30\n7680/7680 [==============================] - 1s 144us/step - loss: 0.6976 - acc: 0.5096 - val_loss: 0.6969 - val_acc: 0.5458\nEpoch 11/30\n7680/7680 [==============================] - 1s 140us/step - loss: 0.6972 - acc: 0.5120 - val_loss: 0.6961 - val_acc: 0.4958\nEpoch 12/30\n7680/7680 [==============================] - 1s 159us/step - loss: 0.6970 - acc: 0.5107 - val_loss: 0.6948 - val_acc: 0.4958\nEpoch 13/30\n7680/7680 [==============================] - 1s 158us/step - loss: 0.6953 - acc: 0.5082 - val_loss: 0.6946 - val_acc: 0.5026\nEpoch 14/30\n7680/7680 [==============================] - 1s 150us/step - loss: 0.6946 - acc: 0.5105 - val_loss: 0.6956 - val_acc: 0.4958\nEpoch 15/30\n7680/7680 [==============================] - 1s 142us/step - loss: 0.6946 - acc: 0.5056 - val_loss: 0.6946 - val_acc: 0.4958\nEpoch 16/30\n7680/7680 [==============================] - 1s 143us/step - loss: 0.6946 - acc: 0.5059 - val_loss: 0.6936 - val_acc: 0.4958\nEpoch 17/30\n7680/7680 [==============================] - 1s 145us/step - loss: 0.6943 - acc: 0.4941 - val_loss: 0.6938 - val_acc: 0.4958\nEpoch 18/30\n7680/7680 [==============================] - 1s 147us/step - loss: 0.6938 - acc: 0.5090 - val_loss: 0.6947 - val_acc: 0.4958\nEpoch 19/30\n7680/7680 [==============================] - 1s 166us/step - loss: 0.6942 - acc: 0.4980 - val_loss: 0.6935 - val_acc: 0.4958\nEpoch 20/30\n7680/7680 [==============================] - 1s 175us/step - loss: 0.6941 - acc: 0.4957 - val_loss: 0.6939 - val_acc: 0.4958\nEpoch 21/30\n7680/7680 [==============================] - 1s 144us/step - loss: 0.6942 - acc: 0.4948 - val_loss: 0.6936 - val_acc: 0.4958\nEpoch 22/30\n7680/7680 [==============================] - 1s 182us/step - loss: 0.6934 - acc: 0.4991 - val_loss: 0.6932 - val_acc: 0.4958\nEpoch 23/30\n7680/7680 [==============================] - 1s 141us/step - loss: 0.6932 - acc: 0.4954 - val_loss: 0.6932 - val_acc: 0.4958\nEpoch 24/30\n7680/7680 [==============================] - 1s 140us/step - loss: 0.6932 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4958\nEpoch 25/30\n7680/7680 [==============================] - 1s 138us/step - loss: 0.6932 - acc: 0.5017 - val_loss: 0.6933 - val_acc: 0.4958\nEpoch 26/30\n7680/7680 [==============================] - 1s 142us/step - loss: 0.6933 - acc: 0.4993 - val_loss: 0.6933 - val_acc: 0.4958\nEpoch 27/30\n7680/7680 [==============================] - 1s 146us/step - loss: 0.6932 - acc: 0.5035 - val_loss: 0.6933 - val_acc: 0.4958\nEpoch 28/30\n7680/7680 [==============================] - 2s 206us/step - loss: 0.6932 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4958\nEpoch 29/30\n7680/7680 [==============================] - 1s 149us/step - loss: 0.6932 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4958\nEpoch 30/30\n7680/7680 [==============================] - 1s 165us/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6932 - val_acc: 0.4958\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"3ae4f039d0b614086acabc2cca68a5ce102bd924"},"cell_type":"code","source":"y_hat_2 = model_2.predict(X_test)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98f136828c411234d9a3175feb9ebf0669739527"},"cell_type":"code","source":"accuracy_score(list(map(lambda x: np.argmax(x), y_test)), list(map(lambda x: np.argmax(x), y_hat_2)))","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"0.4920833333333333"},"metadata":{}}]},{"metadata":{"_uuid":"5268ddd4d449ce7540b7ef7269427e921731e3e8"},"cell_type":"markdown","source":"# Model 2: Glove with trainable embeddings\n\nFor this model we're going to try the same model again, but this time make the embeddings trainable. That means if during training the model decides on a better embedding for a word then it'll update it\n\nThis has the added benifit of updating the words which were randomly assigned a vector (because they weren't in the w2v model)"},{"metadata":{"trusted":true,"_uuid":"c36ceefeeaa74f76bae42c5ac4d39691d6caa219"},"cell_type":"code","source":"inputs_3 = Input(shape=(sequence_length,), dtype='int32')\nembedding_layer_3 = Embedding(num_words,\n                            embedding_dim,\n                            embeddings_initializer=Constant(embedding_matrix),\n                            input_length=sequence_length,\n                            trainable=True)(inputs_3)\n\nreshape_3 = Reshape((sequence_length, embedding_dim, 1))(embedding_layer_3)\n\n# note the relu activation\nconv_0_3 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_3)\nconv_1_3 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_3)\nconv_2_3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_3)\n\nmaxpool_0_3 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_3)\nmaxpool_1_3 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_3)\nmaxpool_2_3 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_3)\n\nconcatenated_tensor_3 = Concatenate(axis=1)([maxpool_0_3, maxpool_1_3, maxpool_2_3])\nflatten_3 = Flatten()(concatenated_tensor_3)\n\ndropout_3 = Dropout(0.5)(flatten_3)\noutput_3 = Dense(units=2, activation='softmax')(dropout_3)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4560d13f8279ab60e5032ae79b3e30430220109e"},"cell_type":"code","source":"model_3 = Model(inputs=inputs_3, outputs=output_3)\nmodel_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model_3.summary())","execution_count":50,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_7 (InputLayer)            (None, 52)           0                                            \n__________________________________________________________________________________________________\nembedding_7 (Embedding)         (None, 52, 50)       630000      input_7[0][0]                    \n__________________________________________________________________________________________________\nreshape_7 (Reshape)             (None, 52, 50, 1)    0           embedding_7[0][0]                \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 50, 1, 100)   15100       reshape_7[0][0]                  \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 49, 1, 100)   20100       reshape_7[0][0]                  \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 48, 1, 100)   25100       reshape_7[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_19 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_20 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_21 (MaxPooling2D) (None, 1, 1, 100)    0           conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 3, 1, 100)    0           max_pooling2d_19[0][0]           \n                                                                 max_pooling2d_20[0][0]           \n                                                                 max_pooling2d_21[0][0]           \n__________________________________________________________________________________________________\nflatten_7 (Flatten)             (None, 300)          0           concatenate_7[0][0]              \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 300)          0           flatten_7[0][0]                  \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 2)            602         dropout_7[0][0]                  \n==================================================================================================\nTotal params: 690,902\nTrainable params: 690,902\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"db3b163e78d48fbaff9de0847548aad06b2bc90f"},"cell_type":"code","source":"batch_size = 32\nhistory_3 = model_3.fit(X_train, y_train, epochs=30, batch_size=batch_size, verbose=1, validation_split=0.2)","execution_count":51,"outputs":[{"output_type":"stream","text":"Train on 7680 samples, validate on 1920 samples\nEpoch 1/30\n7680/7680 [==============================] - 2s 260us/step - loss: 1.1809 - acc: 0.5400 - val_loss: 0.7157 - val_acc: 0.5047\nEpoch 2/30\n7680/7680 [==============================] - 1s 164us/step - loss: 0.7202 - acc: 0.5690 - val_loss: 0.7181 - val_acc: 0.7161\nEpoch 3/30\n7680/7680 [==============================] - 1s 163us/step - loss: 0.7257 - acc: 0.5905 - val_loss: 0.7177 - val_acc: 0.5714\nEpoch 4/30\n7680/7680 [==============================] - 1s 163us/step - loss: 0.7209 - acc: 0.6758 - val_loss: 0.7554 - val_acc: 0.5625\nEpoch 5/30\n7680/7680 [==============================] - 1s 189us/step - loss: 0.6896 - acc: 0.7723 - val_loss: 0.6792 - val_acc: 0.7927\nEpoch 6/30\n7680/7680 [==============================] - 1s 153us/step - loss: 0.6394 - acc: 0.8253 - val_loss: 0.6373 - val_acc: 0.8245\nEpoch 7/30\n7680/7680 [==============================] - 1s 155us/step - loss: 0.5691 - acc: 0.8602 - val_loss: 0.6061 - val_acc: 0.8396\nEpoch 8/30\n7680/7680 [==============================] - 1s 154us/step - loss: 0.5239 - acc: 0.8846 - val_loss: 0.5734 - val_acc: 0.8474\nEpoch 9/30\n7680/7680 [==============================] - 1s 153us/step - loss: 0.4815 - acc: 0.9030 - val_loss: 0.5417 - val_acc: 0.8516\nEpoch 10/30\n7680/7680 [==============================] - 1s 158us/step - loss: 0.4599 - acc: 0.9092 - val_loss: 0.5484 - val_acc: 0.8594\nEpoch 11/30\n7680/7680 [==============================] - 1s 157us/step - loss: 0.4244 - acc: 0.9236 - val_loss: 0.5314 - val_acc: 0.8646\nEpoch 12/30\n7680/7680 [==============================] - 1s 157us/step - loss: 0.4081 - acc: 0.9223 - val_loss: 0.5491 - val_acc: 0.8656\nEpoch 13/30\n7680/7680 [==============================] - 1s 179us/step - loss: 0.3844 - acc: 0.9335 - val_loss: 0.5061 - val_acc: 0.8729\nEpoch 14/30\n7680/7680 [==============================] - 1s 192us/step - loss: 0.3678 - acc: 0.9393 - val_loss: 0.5072 - val_acc: 0.8661\nEpoch 15/30\n7680/7680 [==============================] - 2s 218us/step - loss: 0.3477 - acc: 0.9470 - val_loss: 0.5247 - val_acc: 0.8714\nEpoch 16/30\n7680/7680 [==============================] - 1s 154us/step - loss: 0.3312 - acc: 0.9495 - val_loss: 0.5227 - val_acc: 0.8604\nEpoch 17/30\n7680/7680 [==============================] - 1s 157us/step - loss: 0.3404 - acc: 0.9470 - val_loss: 0.5361 - val_acc: 0.8661\nEpoch 18/30\n7680/7680 [==============================] - 1s 158us/step - loss: 0.3207 - acc: 0.9548 - val_loss: 0.4684 - val_acc: 0.8781\nEpoch 19/30\n7680/7680 [==============================] - 1s 168us/step - loss: 0.3042 - acc: 0.9577 - val_loss: 0.4879 - val_acc: 0.8771\nEpoch 20/30\n7680/7680 [==============================] - 1s 164us/step - loss: 0.2927 - acc: 0.9590 - val_loss: 0.5024 - val_acc: 0.8698\nEpoch 21/30\n7680/7680 [==============================] - 1s 158us/step - loss: 0.2825 - acc: 0.9641 - val_loss: 0.4714 - val_acc: 0.8745\nEpoch 22/30\n7680/7680 [==============================] - 1s 188us/step - loss: 0.2872 - acc: 0.9625 - val_loss: 0.4781 - val_acc: 0.8797\nEpoch 23/30\n7680/7680 [==============================] - 1s 168us/step - loss: 0.2749 - acc: 0.9647 - val_loss: 0.4985 - val_acc: 0.8750\nEpoch 24/30\n7680/7680 [==============================] - 1s 167us/step - loss: 0.2882 - acc: 0.9594 - val_loss: 0.6517 - val_acc: 0.8438\nEpoch 25/30\n7680/7680 [==============================] - 1s 162us/step - loss: 0.2773 - acc: 0.9637 - val_loss: 0.5473 - val_acc: 0.8724\nEpoch 26/30\n7680/7680 [==============================] - 1s 161us/step - loss: 0.2551 - acc: 0.9693 - val_loss: 0.4867 - val_acc: 0.8729\nEpoch 27/30\n7680/7680 [==============================] - 1s 160us/step - loss: 0.2653 - acc: 0.9650 - val_loss: 0.4918 - val_acc: 0.8708\nEpoch 28/30\n7680/7680 [==============================] - 1s 159us/step - loss: 0.2492 - acc: 0.9699 - val_loss: 0.4930 - val_acc: 0.8698\nEpoch 29/30\n7680/7680 [==============================] - 1s 153us/step - loss: 0.2411 - acc: 0.9715 - val_loss: 0.6409 - val_acc: 0.8620\nEpoch 30/30\n7680/7680 [==============================] - 1s 167us/step - loss: 0.2377 - acc: 0.9737 - val_loss: 0.5199 - val_acc: 0.8677\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"581bc847d6b10330d76eacfc22fdafe66f961fb2"},"cell_type":"code","source":"y_hat_3 = model_3.predict(X_test)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54f6dd1fd37ec8a8fdf8ec75f814c4c6e54261c"},"cell_type":"code","source":"accuracy_score(list(map(lambda x: np.argmax(x), y_test)), list(map(lambda x: np.argmax(x), y_hat_3)))","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"0.8858333333333334"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}